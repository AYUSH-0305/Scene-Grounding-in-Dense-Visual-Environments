# Visual Grounding with Flickr30k Entities

This project implements a **visual grounding** system using the Flickr30k Entities dataset.  
It allows you to train a state-of-the-art model for grounding natural language phrases in images and interactively test predictions via a GUI.

---

## ğŸ“‚ Project Structure

```
visual_grounding/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ flickr30k_entities/
â”‚       â”œâ”€â”€ annotations/
â”‚       â”œâ”€â”€ images/
â”‚       â””â”€â”€ Sentences/
â”‚
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ weights/
â”‚       â””â”€â”€ new_sota_train/
â”‚           â””â”€â”€ new_sota_model_epoch_13.pth
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ explore_data.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ model_advanced.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ run_gui.py
â”œâ”€â”€ train_new_sota.py
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup & Installation

### Prerequisites
- Python **3.8+**
- NVIDIA GPU with CUDA (recommended for training)

### Installation Steps
```bash
# Clone the repository
git clone <your-repo-url>
cd visual_grounding

# Create a virtual environment
python -m venv venv

# Activate the virtual environment
# Linux/Mac:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# Install dependencies
pip install torch torchvision transformers timm Pillow
```

---

## ğŸ“¦ Dataset Setup

This project uses the **Flickr30k Entities** dataset.

1. **Download Dataset**  
   Get the dataset from the official source and extract it.

2. **Organize Data**  
   Place files in:
   ```
   data/flickr30k_entities/
       â”œâ”€â”€ annotations/
       â”œâ”€â”€ images/
       â””â”€â”€ Sentences/
   ```

3. **Update Paths**  
   In both:
   - `train_new_sota.py`
   - `run_gui.py`

   Set:
   ```python
   BASE_DATA_DIR = r"C:\projects\AIMS_TASK\visual_grounding\data\flickr30k_entities"
   ```
   *(Replace with your actual absolute path)*

---

## ğŸš€ Training the Model

To train from scratch:
```bash
python train_new_sota.py
```

- Uses GPU if available.
- Model weights are saved in:
  ```
  outputs/weights/new_sota_train/
  ```

---

## ğŸ–¥ Running the GUI

1. **Set Model Path** in `run_gui.py`:
```python
MODEL_WEIGHTS_PATH = r"outputs/weights/new_sota_train/new_sota_model_epoch_13.pth"
```

2. **Run GUI**:
```bash
python run_gui.py
```

3. **Usage**:
   - Enter **Image ID** from Flickr30k (e.g., `36979`).
   - Enter a **Text Prompt** describing the object (e.g., `a green table`).
   - Click **Run Prediction** to see:
     - Original image
     - Predicted bounding box

---

## ğŸ“Œ Notes
- GPU acceleration is recommended for faster training and inference.
- Hyperparameters (batch size, learning rate) can be adjusted in `train_new_sota.py`.

---

## ğŸ“œ License
This project is for research and educational purposes. Please verify dataset licensing before use.
